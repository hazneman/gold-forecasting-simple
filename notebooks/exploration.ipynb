{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839576cd",
   "metadata": {},
   "source": [
    "# Gold Price Forecasting - Exploration and Analysis\n",
    "\n",
    "This notebook provides comprehensive exploration and analysis for gold price forecasting using various machine learning techniques.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Loading](#setup)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "3. [Feature Engineering](#features)\n",
    "4. [Model Training and Comparison](#models)\n",
    "5. [Visualization and Results](#visualization)\n",
    "6. [Performance Evaluation](#evaluation)\n",
    "7. [Risk Analysis](#risk)\n",
    "8. [Backtesting](#backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6f9da",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b465780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data_collection import GoldDataCollector\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "from src.models import create_model, ModelEnsemble\n",
    "from src.visualization import GoldPriceVisualizer\n",
    "from src.risk_management import RiskManager\n",
    "from src.backtesting import Backtester, BacktestConfig, MovingAverageCrossoverStrategy\n",
    "from config.settings import get_settings\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "settings = get_settings()\n",
    "print(f\"Configuration loaded - Default model: {settings.model.default_model}\")\n",
    "print(f\"Data source: {settings.data_source.default_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36688f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect gold price data\n",
    "collector = GoldDataCollector()\n",
    "\n",
    "# Define date range\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.now() - timedelta(days=1095)).strftime(\"%Y-%m-%d\")  # 3 years\n",
    "\n",
    "print(f\"Collecting data from {start_date} to {end_date}\")\n",
    "\n",
    "# Fetch data\n",
    "raw_data = collector.get_gold_prices(start_date, end_date)\n",
    "print(f\"✅ Collected {len(raw_data)} records\")\n",
    "print(f\"Date range: {raw_data.index.min()} to {raw_data.index.max()}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nData shape:\", raw_data.shape)\n",
    "print(\"\\nColumns:\", raw_data.columns.tolist())\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68159af",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis {#eda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f554d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=== BASIC STATISTICS ===\")\n",
    "print(raw_data.describe())\n",
    "\n",
    "print(\"\\n=== DATA INFO ===\")\n",
    "print(raw_data.info())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(raw_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price trend visualization\n",
    "visualizer = GoldPriceVisualizer()\n",
    "visualizer.plot_price_trend(raw_data, title=\"Gold Price Trend (3 Years)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38280318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Closing price histogram\n",
    "axes[0, 0].hist(raw_data['Close'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Closing Prices')\n",
    "axes[0, 0].set_xlabel('Price ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Daily returns\n",
    "returns = raw_data['Close'].pct_change().dropna()\n",
    "axes[0, 1].hist(returns, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution of Daily Returns')\n",
    "axes[0, 1].set_xlabel('Daily Return')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Volume distribution\n",
    "if 'Volume' in raw_data.columns:\n",
    "    axes[1, 0].hist(raw_data['Volume'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_title('Distribution of Volume')\n",
    "    axes[1, 0].set_xlabel('Volume')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Price volatility (30-day rolling std)\n",
    "volatility = returns.rolling(30).std()\n",
    "axes[1, 1].plot(volatility.index, volatility.values)\n",
    "axes[1, 1].set_title('30-Day Rolling Volatility')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Volatility')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average daily return: {returns.mean():.4f}\")\n",
    "print(f\"Daily volatility: {returns.std():.4f}\")\n",
    "print(f\"Annualized volatility: {returns.std() * np.sqrt(252):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525066c4",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering {#features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature engineer\n",
    "fe = FeatureEngineer()\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Creating features...\")\n",
    "featured_data = fe.create_all_features(raw_data)\n",
    "\n",
    "print(f\"✅ Feature engineering complete!\")\n",
    "print(f\"Original features: {raw_data.shape[1]}\")\n",
    "print(f\"Engineered features: {featured_data.shape[1]}\")\n",
    "print(f\"Added {featured_data.shape[1] - raw_data.shape[1]} new features\")\n",
    "\n",
    "# Display feature names\n",
    "print(\"\\nFeature categories:\")\n",
    "feature_names = featured_data.columns.tolist()\n",
    "technical_features = [f for f in feature_names if any(x in f for x in ['sma', 'ema', 'rsi', 'macd', 'bb_'])]\n",
    "time_features = [f for f in feature_names if any(x in f for x in ['year', 'month', 'day', 'quarter', '_sin', '_cos'])]\n",
    "lag_features = [f for f in feature_names if 'lag' in f]\n",
    "rolling_features = [f for f in feature_names if 'rolling' in f]\n",
    "\n",
    "print(f\"Technical indicators: {len(technical_features)}\")\n",
    "print(f\"Time features: {len(time_features)}\")\n",
    "print(f\"Lag features: {len(lag_features)}\")\n",
    "print(f\"Rolling features: {len(rolling_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize technical indicators\n",
    "visualizer.plot_technical_indicators(featured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# Select numeric features for correlation\n",
    "numeric_features = featured_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Limit to avoid too large correlation matrix\n",
    "sample_features = numeric_features[:30] if len(numeric_features) > 30 else numeric_features\n",
    "\n",
    "visualizer.plot_correlation_matrix(featured_data, sample_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2ff05",
   "metadata": {},
   "source": [
    "## 4. Model Training and Comparison {#models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Remove rows with NaN values\n",
    "clean_data = featured_data.dropna()\n",
    "\n",
    "# Features and target\n",
    "X = clean_data.select_dtypes(include=[np.number]).drop('Close', axis=1, errors='ignore')\n",
    "y = clean_data['Close']\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {X.columns.tolist()[:10]}...\")  # Show first 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (time series split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use time-based split to avoid data leakage\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training period: {X_train.index[0]} to {X_train.index[-1]}\")\n",
    "print(f\"Test period: {X_test.index[0]} to {X_test.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44912fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Linear Regression': create_model('linear'),\n",
    "    'Ridge Regression': create_model('ridge', alpha=1.0),\n",
    "    'Random Forest': create_model('random_forest', n_estimators=100),\n",
    "    # Add more models as needed\n",
    "}\n",
    "\n",
    "# Train models and collect results\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        pred = model.predict(X_test)\n",
    "        predictions[name] = pred\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = model.evaluate(X_test, y_test)\n",
    "        results[name] = metrics\n",
    "        \n",
    "        print(f\"✅ {name} - RMSE: {metrics['rmse']:.2f}, R²: {metrics['r2']:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error training {name}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Model training complete! Trained {len(results)} models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1337a",
   "metadata": {},
   "source": [
    "## 5. Visualization and Results {#visualization}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742baadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "if results:\n",
    "    visualizer.plot_model_comparison(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "if predictions:\n",
    "    visualizer.plot_predictions_vs_actual(y_test, predictions, \n",
    "                                         title=\"Model Predictions vs Actual Gold Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for tree-based models)\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, 'get_feature_importance'):\n",
    "        try:\n",
    "            importance = model.get_feature_importance()\n",
    "            visualizer.plot_feature_importance(importance, top_n=15, \n",
    "                                             title=f\"Feature Importance - {name}\")\n",
    "        except:\n",
    "            print(f\"Could not get feature importance for {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579e77f",
   "metadata": {},
   "source": [
    "## 6. Performance Evaluation {#evaluation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f81fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed performance analysis\n",
    "if results:\n",
    "    print(\"=== MODEL PERFORMANCE SUMMARY ===\")\n",
    "    performance_df = pd.DataFrame(results).T\n",
    "    print(performance_df.round(4))\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = performance_df['r2'].idxmax()\n",
    "    print(f\"\\n🏆 Best model: {best_model} (R² = {performance_df.loc[best_model, 'r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1351c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis for best model\n",
    "if predictions and results:\n",
    "    best_model_name = performance_df['r2'].idxmax()\n",
    "    best_predictions = predictions[best_model_name]\n",
    "    \n",
    "    visualizer.plot_residuals(y_test, best_predictions, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836bf9f",
   "metadata": {},
   "source": [
    "## 7. Risk Analysis {#risk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk analysis\n",
    "risk_manager = RiskManager()\n",
    "\n",
    "# Generate risk report\n",
    "risk_report = risk_manager.generate_risk_report(featured_data['Close'])\n",
    "\n",
    "print(\"=== RISK ANALYSIS REPORT ===\")\n",
    "print(\"\\nReturn Metrics:\")\n",
    "for key, value in risk_report['return_metrics'].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nRisk Metrics:\")\n",
    "for key, value in risk_report['risk_metrics'].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nPosition Sizing:\")\n",
    "for key, value in risk_report['position_sizing'].items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawdown analysis\n",
    "drawdown_info = risk_manager.calculate_maximum_drawdown(featured_data['Close'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.fill_between(drawdown_info['drawdown_series'].index, \n",
    "                drawdown_info['drawdown_series'].values, 0, \n",
    "                alpha=0.7, color='red', label='Drawdown')\n",
    "ax.set_title('Portfolio Drawdown Over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Drawdown (%)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Maximum Drawdown: {drawdown_info['max_drawdown']:.2f}%\")\n",
    "print(f\"Max Drawdown Date: {drawdown_info['max_drawdown_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3bf63",
   "metadata": {},
   "source": [
    "## 8. Backtesting {#backtest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ab843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting with simple moving average strategy\n",
    "config = BacktestConfig(\n",
    "    initial_capital=100000,\n",
    "    commission=0.001,\n",
    "    position_fraction=0.1\n",
    ")\n",
    "\n",
    "# Create strategy\n",
    "strategy = MovingAverageCrossoverStrategy(short_window=10, long_window=20)\n",
    "\n",
    "# Run backtest\n",
    "backtester = Backtester(config)\n",
    "backtest_results = backtester.run_backtest(featured_data, strategy)\n",
    "\n",
    "print(\"=== BACKTESTING RESULTS ===\")\n",
    "print(f\"Strategy: {backtest_results['strategy_name']}\")\n",
    "print(f\"Total Return: {backtest_results['total_return']:.2f}%\")\n",
    "print(f\"Annualized Return: {backtest_results['annualized_return']:.2f}%\")\n",
    "print(f\"Volatility: {backtest_results['volatility']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {backtest_results['sharpe_ratio']:.2f}\")\n",
    "print(f\"Max Drawdown: {backtest_results['max_drawdown']['max_drawdown']:.2f}%\")\n",
    "print(f\"Total Trades: {backtest_results['total_trades']}\")\n",
    "print(f\"Win Rate: {backtest_results['win_rate']:.2f}%\")\n",
    "print(f\"Final Portfolio Value: ${backtest_results['final_portfolio_value']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot portfolio performance\n",
    "portfolio_values = backtest_results['portfolio_values']\n",
    "buy_hold_values = (featured_data['Close'] / featured_data['Close'].iloc[0]) * config.initial_capital\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.plot(portfolio_values.index, portfolio_values.values, \n",
    "        label=f'{strategy.name} Strategy', linewidth=2)\n",
    "ax.plot(buy_hold_values.index, buy_hold_values.values, \n",
    "        label='Buy & Hold', linewidth=2, alpha=0.7)\n",
    "\n",
    "ax.set_title('Strategy Performance vs Buy & Hold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Portfolio Value ($)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate buy & hold performance\n",
    "buy_hold_return = (buy_hold_values.iloc[-1] / buy_hold_values.iloc[0] - 1) * 100\n",
    "print(f\"\\nBuy & Hold Return: {buy_hold_return:.2f}%\")\n",
    "print(f\"Strategy Outperformance: {backtest_results['total_return'] - buy_hold_return:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c221dba",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook has provided a comprehensive analysis of gold price forecasting including:\n",
    "\n",
    "1. **Data Collection**: Historical gold price data spanning 3 years\n",
    "2. **Feature Engineering**: Creation of technical indicators, time features, and statistical measures\n",
    "3. **Model Training**: Comparison of multiple machine learning models\n",
    "4. **Performance Evaluation**: Detailed analysis of model accuracy and reliability\n",
    "5. **Risk Analysis**: Comprehensive risk metrics and drawdown analysis\n",
    "6. **Backtesting**: Strategy performance evaluation with transaction costs\n",
    "\n",
    "### Key Findings:\n",
    "- [To be filled based on actual results]\n",
    "- [Model performance insights]\n",
    "- [Risk characteristics]\n",
    "- [Strategy effectiveness]\n",
    "\n",
    "### Next Steps:\n",
    "1. Experiment with additional features (economic indicators, sentiment data)\n",
    "2. Implement more sophisticated models (neural networks, ensemble methods)\n",
    "3. Develop more complex trading strategies\n",
    "4. Integrate real-time data feeds\n",
    "5. Deploy models in production environment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
